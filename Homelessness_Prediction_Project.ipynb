{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Homelessness Prediction Project.ipynb",
      "provenance": [],
      "toc_visible": true,
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/ananyaa06/Create-A-Thon-Fantastic-4/blob/main/Homelessness_Prediction_Project.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Link to data source (also has the link to the data dictionary)  https://www.huduser.gov/portal/datasets//hpmd.html"
      ],
      "metadata": {
        "id": "r-8Ay_jcfxKv"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Sc-Fx2ahfVAG"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import numpy as np"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "dataset = pd.read_csv(\"https://www.huduser.gov/portal/sites/default/files/xls/05b_analysis_file_update.csv\")"
      ],
      "metadata": {
        "id": "CMtsmcn_fdmb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# FUNCTIONS"
      ],
      "metadata": {
        "id": "vBSbf5UcXRD7"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def generate_data(outcome_var):\n",
        "\n",
        "  # CREATE LISTS FOR OUTCOME VARIABLES\n",
        "  outcomes = list(dataset.keys())[2:5] + [\"pit_miss\", \n",
        "                                        \"odd_flag\", \n",
        "                                        \"pit_hless_balance\", \n",
        "                                        \"pit_shelt_balance\", \n",
        "                                        \"pit_unshelt_balance\", \n",
        "                                        \"unbalance_flag\", \n",
        "                                        \"pit_shelt_pit_hud_share\", \n",
        "                                        \"pit_unshelt_pit_hud_share\",\n",
        "                                        \"pit_hless_pit_hud_share\",\n",
        "                                        \"missing\"]\n",
        "                                        \n",
        "  secondary_outcomes = list(dataset.keys())[5:14] + list(dataset.keys())[17:22]\n",
        "\n",
        "  # ISOLATE TRAINING FEATURES FROM TOTAL DATASET\n",
        "  features_df = dataset.drop([\"year\", \"cocnumber\", \"coctag\", \"panelvar\", \"state_abr\"] + outcomes + secondary_outcomes, axis=1, inplace=False)\n",
        "\n",
        "  # CREATE DATAFRAME OF ALL OUTCOME VARIABLE DATA\n",
        "  possible_outcomes_df = dataset[outcomes + secondary_outcomes]\n",
        "\n",
        "  # IDENTIFY (AND DROP) FEATURES WITH MANY NAN VALUES\n",
        "  NaN_features = []\n",
        "\n",
        "  for key in features_df.keys():\n",
        "    if features_df[key].isna().sum() > 300:\n",
        "      NaN_features.append(key)\n",
        "\n",
        "  features_df.drop(NaN_features, axis=1, inplace=True)\n",
        "\n",
        "  # FILL IN THE FEW REMAINING NAN VALUES WITH COLUMN-WISE AVERAGE\n",
        "  for key in features_df.keys():\n",
        "    # print(key)\n",
        "    features_df[key].fillna(value=round(features_df[key].mean()), inplace=True)\n",
        "\n",
        "  # ADDING OUTCOME VAR TO THE END OF THE DATASET\n",
        "  features_df[outcome_var] = possible_outcomes_df[outcome_var]\n",
        "\n",
        "  # DROP THE NAN VALUES THAT ARE PRESENT IN THE OUTCOME VAR\n",
        "  final_df = features_df.dropna()\n",
        "  print(final_df.shape)\n",
        "\n",
        "  return final_df\n"
      ],
      "metadata": {
        "id": "tq8h81OpPruK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def get_train_test_data(data):\n",
        "\n",
        "  X = data.iloc[:, :-1].values\n",
        "  y = data.iloc[:, -1].values\n",
        "  #I just wrote this assuming we're using the last variable for the predicted variable but we can change it accordingly\n",
        "\n",
        "  from sklearn.model_selection import train_test_split\n",
        "  X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.25, random_state = 6)\n",
        "\n",
        "  from sklearn.preprocessing import StandardScaler\n",
        "  sc = StandardScaler()\n",
        "  X_train = sc.fit_transform(X_train)\n",
        "  X_test = sc.transform(X_test)\n",
        "\n",
        "  return X_train, X_test, y_train, y_test"
      ],
      "metadata": {
        "id": "o-eBfYesdFuf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# function for training and testing different models\n",
        "\n",
        "def train_and_test_func(X_train, X_test, y_train, y_test, graph_title):\n",
        "\n",
        "  from sklearn.linear_model import LinearRegression, ElasticNet, Ridge, Lasso, BayesianRidge\n",
        "  import matplotlib.pyplot as plt\n",
        "\n",
        "  models = []\n",
        "  scores = []\n",
        "\n",
        "  print(\"Model:\".ljust(20), \"R2 Score:\")\n",
        "  print()\n",
        "\n",
        "  lr = LinearRegression()\n",
        "  lr.fit(X_train, y_train)\n",
        "  print(\"Linear Regression:\".ljust(20), lr.score(X_test, y_test))\n",
        "  models.append(\"Linear Regression\")\n",
        "  scores.append(round(lr.score(X_test, y_test), 3))\n",
        "\n",
        "  en = ElasticNet()\n",
        "  en.fit(X_train, y_train)\n",
        "  print(\"ElasticNet:\".ljust(20), en.score(X_test, y_test))\n",
        "  models.append(\"ElasticNet\")\n",
        "  scores.append(round(en.score(X_test, y_test), 3))\n",
        "\n",
        "  rd = Ridge()\n",
        "  rd.fit(X_train, y_train)\n",
        "  print(\"Ridge:\".ljust(20), rd.score(X_test, y_test))\n",
        "  models.append(\"Ridge\")\n",
        "  scores.append(round(rd.score(X_test, y_test), 3))\n",
        "\n",
        "  ls = Lasso()\n",
        "  ls.fit(X_train, y_train)\n",
        "  print(\"Lasso:\".ljust(20), ls.score(X_test, y_test))\n",
        "  models.append(\"Lasso\")\n",
        "  scores.append(round(ls.score(X_test, y_test), 3))\n",
        "\n",
        "  br = BayesianRidge()\n",
        "  br.fit(X_train, y_train)\n",
        "  print(\"Bayesian Ridge:\".ljust(20), br.score(X_test, y_test))\n",
        "  models.append(\"Bayesian Ridge\")\n",
        "  scores.append(round(br.score(X_test, y_test), 3))\n",
        "\n",
        "  #---\n",
        "\n",
        "  # y_pos = np.arange(len(models))\n",
        "\n",
        "  # plt.bar(y_pos, scores, align='center', alpha=0.5)\n",
        "  # # add_value_label(models, scores)\n",
        "  # plt.xticks(y_pos, models)\n",
        "  # plt.ylabel('R2 Score')\n",
        "  # plt.title(f\"Performance on: {graph_title}\")\n",
        "\n",
        "  # plt.ylim(0,1)\n",
        "  # plt.xticks(rotation=30, ha='center')\n",
        "\n",
        "  # plt.show()\n",
        "\n",
        "  print()\n",
        "  return scores"
      ],
      "metadata": {
        "id": "dGkYTdyYMcRM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# MODEL EXPERIMENTATION"
      ],
      "metadata": {
        "id": "s90ZdhYVXfY2"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# PRINT NAN COUNT FOR EACH OF THE POSSIBLE OUTCOME VARIABLES\n",
        "\n",
        "outcomes = list(dataset.keys())[2:5] + [\"pit_miss\", \n",
        "                                      \"odd_flag\", \n",
        "                                      \"pit_hless_balance\", \n",
        "                                      \"pit_shelt_balance\", \n",
        "                                      \"pit_unshelt_balance\", \n",
        "                                      \"unbalance_flag\", \n",
        "                                      \"pit_shelt_pit_hud_share\", \n",
        "                                      \"pit_unshelt_pit_hud_share\",\n",
        "                                      \"pit_hless_pit_hud_share\",\n",
        "                                      \"missing\"]\n",
        "                                      \n",
        "secondary_outcomes = list(dataset.keys())[5:14] + list(dataset.keys())[17:22]\n",
        "\n",
        "possible_outcomes_df = dataset[outcomes + secondary_outcomes]\n",
        "\n",
        "#--\n",
        "print(\"Key:\".ljust(35), \"NaN Count\")\n",
        "print()\n",
        "\n",
        "for key in possible_outcomes_df.keys():\n",
        "  print(key.ljust(35), possible_outcomes_df[key].isna().sum())\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "r_0y-I4BDR5R",
        "outputId": "93e73345-e3d6-417c-852e-8850747391d8"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Key:                                NaN Count\n",
            "\n",
            "pit_tot_shelt_pit_hud               14\n",
            "pit_tot_unshelt_pit_hud             14\n",
            "pit_tot_hless_pit_hud               14\n",
            "pit_miss                            0\n",
            "odd_flag                            0\n",
            "pit_hless_balance                   0\n",
            "pit_shelt_balance                   0\n",
            "pit_unshelt_balance                 0\n",
            "unbalance_flag                      0\n",
            "pit_shelt_pit_hud_share             14\n",
            "pit_unshelt_pit_hud_share           14\n",
            "pit_hless_pit_hud_share             14\n",
            "missing                             0\n",
            "pit_ind_shelt_pit_hud               14\n",
            "pit_ind_unshelt_pit_hud             14\n",
            "pit_ind_hless_pit_hud               14\n",
            "pit_perfam_shelt_pit_hud            14\n",
            "pit_perfam_unshelt_pit_hud          14\n",
            "pit_perfam_hless_pit_hud            14\n",
            "pit_ind_chronic_hless_pit_hud       14\n",
            "pit_perfam_chronic_hless_pit_hud    1137\n",
            "pit_vet_hless_pit_hud               387\n",
            "hou_pol_totalind_hud                2259\n",
            "hou_pol_totalday_hud                2259\n",
            "hou_pol_totalexit_hud               2259\n",
            "hou_pol_numret6mos_hud              2259\n",
            "hou_pol_numret12mos_hud             2259\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import matplotlib.pyplot as plt\n",
        "\n",
        "models = [\"Linear Regression\", \"ElasticNet\", \"Ridge\", \"Lasso\", \"Bayesian Ridge\"]\n",
        "x = np.arange(len(models))\n",
        "width = 0.2\n",
        "\n",
        "# GENERATE DATA BASED ON OUTCOME VARIABLE\n",
        "DATA = generate_data(outcome_var = \"pit_tot_shelt_pit_hud\") # ths outcome variable can be adjusted to whatever we want\n",
        "X_train, X_test, y_train, y_test = get_train_test_data(DATA)\n",
        "scores = train_and_test_func(X_train, X_test, y_train, y_test, \"Sheltered Homeless per 10,000\")\n",
        "\n",
        "plt.bar(x-0.2, scores, width, color='darkgoldenrod')\n",
        "\n",
        "# GENERATE DATA BASED ON OUTCOME VARIABLE\n",
        "DATA = generate_data(outcome_var = \"pit_tot_unshelt_pit_hud\") # ths outcome variable can be adjusted to whatever we want\n",
        "X_train, X_test, y_train, y_test = get_train_test_data(DATA)\n",
        "scores = train_and_test_func(X_train, X_test, y_train, y_test, \"Unsheltered Homeless per 10,000\")\n",
        "\n",
        "plt.bar(x, scores, width, color='gold')\n",
        "\n",
        "\n",
        "# GENERATE DATA BASED ON OUTCOME VARIABLE\n",
        "DATA = generate_data(outcome_var = \"pit_tot_hless_pit_hud\") # ths outcome variable can be adjusted to whatever we want\n",
        "X_train, X_test, y_train, y_test = get_train_test_data(DATA)\n",
        "scores = train_and_test_func(X_train, X_test, y_train, y_test, \"Total Homeless per 10,000\")\n",
        "\n",
        "plt.bar(x+0.2, scores, width, color='darkorange')\n",
        "\n",
        "plt.xticks(x, models)\n",
        "plt.xticks(rotation=30, ha=\"center\")\n",
        "plt.xlabel(\"Regression Models\")\n",
        "plt.ylabel(\"R2 Scores\")\n",
        "plt.legend([\"Sheltered Homeless Rate\", \"Unsheltered Homeless Rate\", \"Total Homeless Rate\"], bbox_to_anchor=(1.02, 0.75), loc=\"lower left\", borderaxespad=0)\n",
        "\n",
        "plt.show()\n",
        "\n"
      ],
      "metadata": {
        "id": "PKuO6-D0SQwA",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 915
        },
        "outputId": "10c95a11-4666-4399-ed2f-a94325640d02"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(2994, 190)\n",
            "Model:               R2 Score:\n",
            "\n",
            "Linear Regression:   0.9899263638982593\n",
            "ElasticNet:          0.9640001079830204\n",
            "Ridge:               0.9899883673750962\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.869e+06, tolerance: 2.361e+06\n",
            "  coef_, l1_reg, l2_reg, X, y, max_iter, tol, rng, random, positive\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Lasso:               0.9900745452152064\n",
            "Bayesian Ridge:      0.9899824187506459\n",
            "\n",
            "(2994, 190)\n",
            "Model:               R2 Score:\n",
            "\n",
            "Linear Regression:   0.8274848597311554\n",
            "ElasticNet:          0.7050886023202613\n",
            "Ridge:               0.8130233574301412\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 8.308e+07, tolerance: 6.747e+05\n",
            "  coef_, l1_reg, l2_reg, X, y, max_iter, tol, rng, random, positive\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Lasso:               0.8119341350871482\n",
            "Bayesian Ridge:      0.8054330239788843\n",
            "\n",
            "(2994, 190)\n",
            "Model:               R2 Score:\n",
            "\n",
            "Linear Regression:   0.97348827352747\n",
            "ElasticNet:          0.9455920230172994\n",
            "Ridge:               0.9711179607149042\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.944e+08, tolerance: 3.838e+06\n",
            "  coef_, l1_reg, l2_reg, X, y, max_iter, tol, rng, random, positive\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Lasso:               0.9703609458532152\n",
            "Bayesian Ridge:      0.9697135897530513\n",
            "\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.linear_model import LinearRegression\n",
        "\n",
        "DATA = generate_data(outcome_var = \"pit_tot_shelt_pit_hud\") # ths outcome variable can be adjusted to whatever we want\n",
        "X_train, X_test, y_train, y_test = get_train_test_data(DATA)\n",
        "\n",
        "lr = LinearRegression()\n",
        "lr.fit(X_train, y_train)\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yFbJVi59alhN",
        "outputId": "3d516714-d30c-4ecb-bb68-a79efa2773b5"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(2994, 190)\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "LinearRegression()"
            ]
          },
          "metadata": {},
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "sorted(zip(np.abs(lr.coef_), DATA.keys()), reverse=True)"
      ],
      "metadata": {
        "id": "mbkUu6nIa9rD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "dataset"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 2286
        },
        "id": "Ymz4XuIebQ8U",
        "outputId": "a1d6dd84-3d93-4ef6-c495-69da61ff66e9"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "      year cocnumber  pit_tot_shelt_pit_hud  pit_tot_unshelt_pit_hud  \\\n",
              "0     2010    AK-500                 1113.0                    118.0   \n",
              "1     2011    AK-500                 1082.0                    141.0   \n",
              "2     2012    AK-500                 1097.0                     50.0   \n",
              "3     2013    AK-500                 1070.0                     52.0   \n",
              "4     2014    AK-500                  970.0                     53.0   \n",
              "...    ...       ...                    ...                      ...   \n",
              "3003  2013    WY-500                  501.0                    452.0   \n",
              "3004  2014    WY-500                  563.0                    194.0   \n",
              "3005  2015    WY-500                  507.0                    291.0   \n",
              "3006  2016    WY-500                  491.0                    366.0   \n",
              "3007  2017    WY-500                  510.0                    363.0   \n",
              "\n",
              "      pit_tot_hless_pit_hud  pit_ind_shelt_pit_hud  pit_ind_unshelt_pit_hud  \\\n",
              "0                    1231.0                  633.0                    107.0   \n",
              "1                    1223.0                  677.0                    117.0   \n",
              "2                    1147.0                  756.0                     35.0   \n",
              "3                    1122.0                  792.0                     52.0   \n",
              "4                    1023.0                  688.0                     48.0   \n",
              "...                     ...                    ...                      ...   \n",
              "3003                  953.0                  306.0                    371.0   \n",
              "3004                  757.0                  327.0                    136.0   \n",
              "3005                  798.0                  292.0                    208.0   \n",
              "3006                  857.0                  277.0                    240.0   \n",
              "3007                  873.0                  383.0                    239.0   \n",
              "\n",
              "      pit_ind_hless_pit_hud  pit_perfam_shelt_pit_hud  \\\n",
              "0                     740.0                     480.0   \n",
              "1                     794.0                     405.0   \n",
              "2                     791.0                     341.0   \n",
              "3                     844.0                     278.0   \n",
              "4                     736.0                     282.0   \n",
              "...                     ...                       ...   \n",
              "3003                  677.0                     195.0   \n",
              "3004                  463.0                     236.0   \n",
              "3005                  500.0                     215.0   \n",
              "3006                  517.0                     214.0   \n",
              "3007                  622.0                     127.0   \n",
              "\n",
              "      pit_perfam_unshelt_pit_hud  ...  sub_high_cost_rent75  \\\n",
              "0                           11.0  ...                     1   \n",
              "1                           24.0  ...                     1   \n",
              "2                           15.0  ...                     1   \n",
              "3                            0.0  ...                     1   \n",
              "4                            5.0  ...                     1   \n",
              "...                          ...  ...                   ...   \n",
              "3003                        81.0  ...                     0   \n",
              "3004                        58.0  ...                     1   \n",
              "3005                        83.0  ...                     0   \n",
              "3006                       126.0  ...                     1   \n",
              "3007                       124.0  ...                     0   \n",
              "\n",
              "      sub_high_cost_homeval75  sub_high_rent_share75  \\\n",
              "0                           1                      1   \n",
              "1                           1                      0   \n",
              "2                           1                      1   \n",
              "3                           1                      0   \n",
              "4                           1                      1   \n",
              "...                       ...                    ...   \n",
              "3003                        0                      0   \n",
              "3004                        1                      1   \n",
              "3005                        0                      0   \n",
              "3006                        1                      1   \n",
              "3007                        0                      0   \n",
              "\n",
              "      tight_high_cost_rental_mkt  sub_tight_high_cost_rent  \\\n",
              "0                              3                         1   \n",
              "1                              3                         1   \n",
              "2                              3                         1   \n",
              "3                              3                         1   \n",
              "4                              3                         1   \n",
              "...                          ...                       ...   \n",
              "3003                           0                         0   \n",
              "3004                           3                         1   \n",
              "3005                           0                         0   \n",
              "3006                           3                         1   \n",
              "3007                           0                         0   \n",
              "\n",
              "      sub_west_coast_all_urb  sub_west_census  major_city  suburban  rural  \n",
              "0                          1                1           1         0      0  \n",
              "1                          1                1           1         0      0  \n",
              "2                          1                1           1         0      0  \n",
              "3                          1                1           1         0      0  \n",
              "4                          1                1           1         0      0  \n",
              "...                      ...              ...         ...       ...    ...  \n",
              "3003                       0                1           0         0      1  \n",
              "3004                       0                1           0         0      1  \n",
              "3005                       0                1           0         0      1  \n",
              "3006                       0                1           0         0      1  \n",
              "3007                       0                1           0         0      1  \n",
              "\n",
              "[3008 rows x 332 columns]"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-35f046ae-d171-4d6b-920c-5fb2b337370c\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>year</th>\n",
              "      <th>cocnumber</th>\n",
              "      <th>pit_tot_shelt_pit_hud</th>\n",
              "      <th>pit_tot_unshelt_pit_hud</th>\n",
              "      <th>pit_tot_hless_pit_hud</th>\n",
              "      <th>pit_ind_shelt_pit_hud</th>\n",
              "      <th>pit_ind_unshelt_pit_hud</th>\n",
              "      <th>pit_ind_hless_pit_hud</th>\n",
              "      <th>pit_perfam_shelt_pit_hud</th>\n",
              "      <th>pit_perfam_unshelt_pit_hud</th>\n",
              "      <th>...</th>\n",
              "      <th>sub_high_cost_rent75</th>\n",
              "      <th>sub_high_cost_homeval75</th>\n",
              "      <th>sub_high_rent_share75</th>\n",
              "      <th>tight_high_cost_rental_mkt</th>\n",
              "      <th>sub_tight_high_cost_rent</th>\n",
              "      <th>sub_west_coast_all_urb</th>\n",
              "      <th>sub_west_census</th>\n",
              "      <th>major_city</th>\n",
              "      <th>suburban</th>\n",
              "      <th>rural</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>2010</td>\n",
              "      <td>AK-500</td>\n",
              "      <td>1113.0</td>\n",
              "      <td>118.0</td>\n",
              "      <td>1231.0</td>\n",
              "      <td>633.0</td>\n",
              "      <td>107.0</td>\n",
              "      <td>740.0</td>\n",
              "      <td>480.0</td>\n",
              "      <td>11.0</td>\n",
              "      <td>...</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>3</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>2011</td>\n",
              "      <td>AK-500</td>\n",
              "      <td>1082.0</td>\n",
              "      <td>141.0</td>\n",
              "      <td>1223.0</td>\n",
              "      <td>677.0</td>\n",
              "      <td>117.0</td>\n",
              "      <td>794.0</td>\n",
              "      <td>405.0</td>\n",
              "      <td>24.0</td>\n",
              "      <td>...</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>3</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>2012</td>\n",
              "      <td>AK-500</td>\n",
              "      <td>1097.0</td>\n",
              "      <td>50.0</td>\n",
              "      <td>1147.0</td>\n",
              "      <td>756.0</td>\n",
              "      <td>35.0</td>\n",
              "      <td>791.0</td>\n",
              "      <td>341.0</td>\n",
              "      <td>15.0</td>\n",
              "      <td>...</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>3</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>2013</td>\n",
              "      <td>AK-500</td>\n",
              "      <td>1070.0</td>\n",
              "      <td>52.0</td>\n",
              "      <td>1122.0</td>\n",
              "      <td>792.0</td>\n",
              "      <td>52.0</td>\n",
              "      <td>844.0</td>\n",
              "      <td>278.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>...</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>3</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>2014</td>\n",
              "      <td>AK-500</td>\n",
              "      <td>970.0</td>\n",
              "      <td>53.0</td>\n",
              "      <td>1023.0</td>\n",
              "      <td>688.0</td>\n",
              "      <td>48.0</td>\n",
              "      <td>736.0</td>\n",
              "      <td>282.0</td>\n",
              "      <td>5.0</td>\n",
              "      <td>...</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>3</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3003</th>\n",
              "      <td>2013</td>\n",
              "      <td>WY-500</td>\n",
              "      <td>501.0</td>\n",
              "      <td>452.0</td>\n",
              "      <td>953.0</td>\n",
              "      <td>306.0</td>\n",
              "      <td>371.0</td>\n",
              "      <td>677.0</td>\n",
              "      <td>195.0</td>\n",
              "      <td>81.0</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3004</th>\n",
              "      <td>2014</td>\n",
              "      <td>WY-500</td>\n",
              "      <td>563.0</td>\n",
              "      <td>194.0</td>\n",
              "      <td>757.0</td>\n",
              "      <td>327.0</td>\n",
              "      <td>136.0</td>\n",
              "      <td>463.0</td>\n",
              "      <td>236.0</td>\n",
              "      <td>58.0</td>\n",
              "      <td>...</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>3</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3005</th>\n",
              "      <td>2015</td>\n",
              "      <td>WY-500</td>\n",
              "      <td>507.0</td>\n",
              "      <td>291.0</td>\n",
              "      <td>798.0</td>\n",
              "      <td>292.0</td>\n",
              "      <td>208.0</td>\n",
              "      <td>500.0</td>\n",
              "      <td>215.0</td>\n",
              "      <td>83.0</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3006</th>\n",
              "      <td>2016</td>\n",
              "      <td>WY-500</td>\n",
              "      <td>491.0</td>\n",
              "      <td>366.0</td>\n",
              "      <td>857.0</td>\n",
              "      <td>277.0</td>\n",
              "      <td>240.0</td>\n",
              "      <td>517.0</td>\n",
              "      <td>214.0</td>\n",
              "      <td>126.0</td>\n",
              "      <td>...</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>3</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3007</th>\n",
              "      <td>2017</td>\n",
              "      <td>WY-500</td>\n",
              "      <td>510.0</td>\n",
              "      <td>363.0</td>\n",
              "      <td>873.0</td>\n",
              "      <td>383.0</td>\n",
              "      <td>239.0</td>\n",
              "      <td>622.0</td>\n",
              "      <td>127.0</td>\n",
              "      <td>124.0</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>3008 rows  332 columns</p>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-35f046ae-d171-4d6b-920c-5fb2b337370c')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-35f046ae-d171-4d6b-920c-5fb2b337370c button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-35f046ae-d171-4d6b-920c-5fb2b337370c');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 18
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Warning: Total number of columns (332) exceeds max_columns (20) limiting to first (20) columns.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Code Graveyard"
      ],
      "metadata": {
        "id": "nIOyY4sZTWlW"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# options for our predicted variables\n",
        "outcomes = list(dataset.keys())[2:5] + [\"pit_miss\", \n",
        "                                        \"odd_flag\", \n",
        "                                        \"pit_hless_balance\", \n",
        "                                        \"pit_shelt_balance\", \n",
        "                                        \"pit_unshelt_balance\", \n",
        "                                        \"unbalance_flag\", \n",
        "                                        \"pit_shelt_pit_hud_share\", \n",
        "                                        \"pit_unshelt_pit_hud_share\",\n",
        "                                        \"pit_hless_pit_hud_share\",\n",
        "                                        \"missing\"]\n",
        "                                        \n",
        "secondary_outcomes = list(dataset.keys())[5:14] + list(dataset.keys())[17:22]\n",
        "print(outcomes)\n",
        "print(secondary_outcomes)"
      ],
      "metadata": {
        "id": "EQJqhHCGflrk",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "a5182bf6-385a-47c9-b064-4767f4e86e8d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['pit_tot_shelt_pit_hud', 'pit_tot_unshelt_pit_hud', 'pit_tot_hless_pit_hud', 'pit_miss', 'odd_flag', 'pit_hless_balance', 'pit_shelt_balance', 'pit_unshelt_balance', 'unbalance_flag', 'pit_shelt_pit_hud_share', 'pit_unshelt_pit_hud_share', 'pit_hless_pit_hud_share', 'missing']\n",
            "['pit_ind_shelt_pit_hud', 'pit_ind_unshelt_pit_hud', 'pit_ind_hless_pit_hud', 'pit_perfam_shelt_pit_hud', 'pit_perfam_unshelt_pit_hud', 'pit_perfam_hless_pit_hud', 'pit_ind_chronic_hless_pit_hud', 'pit_perfam_chronic_hless_pit_hud', 'pit_vet_hless_pit_hud', 'hou_pol_totalind_hud', 'hou_pol_totalday_hud', 'hou_pol_totalexit_hud', 'hou_pol_numret6mos_hud', 'hou_pol_numret12mos_hud']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "possible_outcomes_df = dataset[outcomes + secondary_outcomes]"
      ],
      "metadata": {
        "id": "EQ9lPtrtW4SF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# isolate training feaures (dropping identifiers and outcome columns)\n",
        "features_df = dataset.drop([\"year\", \"cocnumber\", \"coctag\", \"panelvar\", \"state_abr\"] + outcomes + secondary_outcomes, axis=1, inplace=False)"
      ],
      "metadata": {
        "id": "qNovZ6RaSn6P"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Identifying features with lots of NaN(missing) values\n",
        "NaN_features = []\n",
        "\n",
        "for key in features_df.keys():\n",
        "  if features_df[key].isna().sum() > 300:\n",
        "    NaN_features.append(key)\n",
        "  # print(key.ljust(35), features_df[key].isna().sum())"
      ],
      "metadata": {
        "id": "rouxePB-e3sq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Dropping the Nan features\n",
        "features_df.drop(NaN_features, axis=1, inplace=True)\n",
        "# features_df"
      ],
      "metadata": {
        "id": "auf6O9e6sDQh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# filling the remaining NaNs with the mean of the column\n",
        "for key in features_df.keys():\n",
        "  # print(key)\n",
        "  features_df[key].fillna(value=round(features_df[key].mean()), inplace=True)"
      ],
      "metadata": {
        "id": "0GFkDIKhALyr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Adding our outcome var to the end of the dataset\n",
        "features_df[outcome_var] = possible_outcomes_df[outcome_var]\n",
        "# features_df"
      ],
      "metadata": {
        "id": "n_8jOGrBFZOy"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "outcome_var = \"pit_tot_shelt_pit_hud\""
      ],
      "metadata": {
        "id": "ob9mEUb-FUeI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Drop the 14 (or however many) NaN values are present in the outcome var\n",
        "dataset = features_df.dropna()"
      ],
      "metadata": {
        "id": "wFmpcIN-F1bz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# I'VE COMMENTED THIS OUT FOR NOW BECAUSE 0 COLUMNS WERE LABEL ENCODED\n",
        "# (still keeping the code in case we need it later)\n",
        "\n",
        "# from sklearn.preprocessing import LabelEncoder\n",
        "# le = LabelEncoder()\n",
        "# le_count = 0\n",
        "# for col in DATA.columns[1:]:\n",
        "#     if DATA[col].dtype == 'object':\n",
        "#         if len(list(DATA[col].unique())) <= 2:\n",
        "#             le.fit(DATA[col])\n",
        "#             DATA[col] = le.transform(DATA[col])\n",
        "#             le_count += 1\n",
        "# print('{} columns were label encoded.'.format(le_count))"
      ],
      "metadata": {
        "id": "5EMyqrKUfmX3",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "0d531cdd-fc83-43a5-bacf-2b49525f417a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0 columns were label encoded.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# I'VE COMMENTED THIS OUT FOR NOW BECAUSE 0 COLUMNS WERE ONE-HOT ENCODED\n",
        "# (still keeping the code in case we need it later)\n",
        "\n",
        "# from sklearn.compose import ColumnTransformer\n",
        "# from sklearn.preprocessing import OneHotEncoder\n",
        "\n",
        "# ct_count = 0\n",
        "# for col in DATA.columns[1:]:\n",
        "#     if DATA[col].dtype == 'object':\n",
        "#         if len(list(DATA[col].unique())) >= 2:\n",
        "#           DATA = pd.concat([DATA,pd.get_dummies(DATA[col], prefix=col)], axis=1)\n",
        "#           DATA.drop([col],axis=1, inplace=True)\n",
        "#           ct_count += 1\n",
        "# print('{} columns were one-hot encoded.'.format(ct_count))\n"
      ],
      "metadata": {
        "id": "5rmv2-uHdFGT",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "e1e85340-92ff-41f1-fa7a-f59c2b7f33b3"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0 columns were one-hot encoded.\n"
          ]
        }
      ]
    }
  ]
}